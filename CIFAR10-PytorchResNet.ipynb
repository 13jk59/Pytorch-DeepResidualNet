{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "import torchsummary\n",
    "from torchsummary import summary\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "import random\n",
    "import torch\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import torch.utils.data\n",
    "import matplotlib\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset workflow\n",
    "## -> read numpy file in -> transform to PIL image -> do PIL image preprocessing \n",
    "## -> convert to tensor (requires inputs in form H*W*C) -> Normalize \n",
    "\n",
    "class Cifar10Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_dir, images_dir, labels_dir, transforms = None):\n",
    "        #initalize images & labels \n",
    "        self.images_path = os.path.join(root_dir, images_dir)\n",
    "        self.labels_path = os.path.join(root_dir, labels_dir)\n",
    "        self.transforms = transforms\n",
    "        self.images = np.load(self.images_path)\n",
    "        # Labels - Get set of unique labels then map them to idx \n",
    "        self.allLabels = np.array(pd.read_csv(self.labels_path)['Category'])\n",
    "        uniqueLabels= set(self.allLabels)\n",
    "        self.labelToIdx = {label:idx for idx,label in enumerate(uniqueLabels)}\n",
    "\n",
    "    def __len__(self):\n",
    "        #returns total number of images in dataset \n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, key):\n",
    "        #generates one sample of data \n",
    "        x = self.images[key]\n",
    "        #transpose image to H*W*C -> required shape as input for torch.tensor() \n",
    "        x = x.transpose(1,2,0)\n",
    "        if self.transforms:\n",
    "            #transform to PIL image and two data augmentations (Random Horziontal Flip and Random GrayScale)\n",
    "            #afterwards transform to a torch tensor and normalize every channel to a range in between [-1,1]\n",
    "            x = self.transforms(x)\n",
    "        # Most loss functions in Pytorch don't take one-hot or binarized vectors (very space inefficient). \n",
    "        # instead take an integer C which represents the class label of a particular image \n",
    "        stringLabel = self.allLabels[key]\n",
    "        y = self.labelToIdx[stringLabel]\n",
    "        # yields one image, fully preprocessed and its corresponding integer label\n",
    "        return x,y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Define Transformations\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(), \n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomGrayscale(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [0.5,0.5,0.5], std=[0.5, 0.5, 0.5])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Cifar10Dataset(root_dir='../input/cifar10-comp/', images_dir='train_images.npy',\n",
    "                    labels_dir='train_labels.csv', transforms=data_transform)\n",
    "labels = x.allLabels\n",
    "z = set(labels)\n",
    "labels_to_idx = {label:idx for idx, label in enumerate(z)}\n",
    "labels_to_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define DataSet\n",
    "transformed_trainData = Cifar10Dataset(root_dir='../input/cifar10-comp/', images_dir='train_images.npy',\n",
    "                                      labels_dir='train_labels.csv', transforms=data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Validation Set\n",
    "train_size = int(0.8*len(transformed_trainData))\n",
    "valid_size = len(transformed_trainData)-train_size\n",
    "train_data, valid_data = torch.utils.data.random_split(transformed_trainData, [train_size, valid_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Generator for Dataset\n",
    "params = {'batch_size':128, 'shuffle':True, 'num_workers':6}\n",
    "training_generator = DataLoader(train_data, **params)\n",
    "\n",
    "validation_generator = DataLoader(valid_data, **params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Images\n",
    "def image_visualizer(dataset):\n",
    "    random.seed(90)\n",
    "    \n",
    "    #Before Preprocessing \n",
    "    plt.figure()\n",
    "    fig, axes = plt.subplots(nrows=3, ncols = 3, figsize = (9,9))\n",
    "    savedIdxs = [] \n",
    "    for idx, axis in enumerate(axes.flatten()):\n",
    "        random_idx = random.randint(0,49999)\n",
    "        savedIdxs.append(random_idx)\n",
    "        random_picture = dataset.images[random_idx].transpose(1,2,0)\n",
    "        label = dataset.allLabels[random_idx]\n",
    "        axis.set_title(label)\n",
    "        axis.imshow(random_picture)\n",
    "    plt.tight_layout()\n",
    "    fig.suptitle('Before Preprocessing')\n",
    "    fig.subplots_adjust(top = 0.93)\n",
    "    plt.show()\n",
    "    \n",
    "    #After Preprocessing\n",
    "    plt.figure()\n",
    "    fig2, axes2 = plt.subplots(nrows=3, ncols = 3, figsize = (9,9))\n",
    "    for idx, axis in enumerate(axes2.flatten()):\n",
    "        random_idx = savedIdxs[idx]\n",
    "        random_picture = dataset[random_idx][0].numpy().transpose(1,2,0)\n",
    "        label = dataset.allLabels[random_idx]\n",
    "        axis.set_title(label)\n",
    "        axis.imshow(random_picture)\n",
    "    plt.tight_layout()\n",
    "    fig2.suptitle('After Preprocessing')\n",
    "    fig2.subplots_adjust(top = 0.93)\n",
    "    plt.show()\n",
    "\n",
    "image_visualizer(transformed_trainData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride =1):\n",
    "        super(ResBlock, self).__init__()\n",
    "        \n",
    "        #First Conv Layer\n",
    "        self.conv1 = nn.Conv2d(kernel_size=(3,3),stride=stride, padding=1, bias= False, in_channels=in_channels, \n",
    "                               out_channels=out_channels)\n",
    "        \n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        #Second Conv Layer\n",
    "        self.conv2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels, \n",
    "                              kernel_size = (3,3), stride = 1, padding=1, bias = False)\n",
    "        \n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        \n",
    "        #Skip connection, downsampled only if the output channels are different than the input channels        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(nn.Conv2d(in_channels=in_channels, \n",
    "                                                   out_channels=out_channels,\n",
    "                                                   kernel_size = (1,1), stride=stride, bias = False),\n",
    "                                         nn.BatchNorm2d(out_channels)\n",
    "                                         )\n",
    "            \n",
    "\n",
    "    def forward(self, x):\n",
    "        out = nn.ReLU()(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = nn.ReLU()(out)\n",
    "        return out\n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, num_classes = 10):\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        #Input Conv\n",
    "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=(3,3), stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(64)\n",
    "        \n",
    "        #Residual Blocks\n",
    "        self.block1 = self._create_block(64, 64, stride=1)\n",
    "        self.block2 = self._create_block(64, 128, stride=2)\n",
    "        self.block3 = self._create_block(128, 256, stride=2)\n",
    "        self.block4 = self._create_block(256, 512, stride =2)\n",
    "        self.linear = nn.Linear(512, num_classes)\n",
    "        \n",
    "    def _create_block(self, in_channels, out_channels, stride):\n",
    "        return nn.Sequential(ResBlock(in_channels, out_channels, stride),\n",
    "                             ResBlock(out_channels, out_channels, 1))\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = nn.ReLU()(self.bn1(self.conv1(x)))\n",
    "        out = self.block1(out)\n",
    "        out = self.block2(out)\n",
    "        out = self.block3(out)\n",
    "        out = self.block4(out)\n",
    "        out = nn.AvgPool2d(4)(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.linear(out)\n",
    "        return out "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize network to train on GPU, using Adam optimization strategy \n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "clf = ResNet()\n",
    "clf.to(device)\n",
    "cost_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(clf.parameters(), lr=0.1, betas=(0.9, 0.999), eps=1e-08, weight_decay=0.00001, amsgrad=False)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.1, patience=5, verbose=True, threshold=0.0001, threshold_mode='rel', cooldown=0, min_lr=0, eps=1e-08)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainResNet(model = clf ,device = device, cost_function = cost_function, optimizer = optimizer, scheduler = scheduler, epochs = 10, training_data = training_generator, validation_data = validation_generator):\n",
    "    training_loss = []\n",
    "    validation_loss = [] \n",
    "    training_accuracy = []\n",
    "    validation_accuracy = [] \n",
    "    epochNum = []\n",
    "    for epoch in range(1, epochs+1):\n",
    "        print('Epoch Num: %s'%(epoch))\n",
    "        epochNum.append(epoch)\n",
    "        epoch_loss = []\n",
    "        epoch_accuracy = [] \n",
    "        start = time.time()\n",
    "        for batch_idx, (inputs, targets) in enumerate(training_data):\n",
    "            # Put the batch on the GPU \n",
    "            \n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            #Forward Pass\n",
    "            \n",
    "            predictions = clf(inputs)\n",
    "            \n",
    "            #Calculate Cost\n",
    "            \n",
    "            loss = cost_function(predictions, targets)\n",
    "            epoch_loss.append(loss.item())\n",
    "            \n",
    "            #Get Train Accuracy\n",
    "            \n",
    "            _, predicted = torch.max(predictions.data, 1)\n",
    "            total = len(targets)\n",
    "            correct = int(torch.sum(predicted == targets.data))\n",
    "            accuracy = (correct/total)*100\n",
    "            epoch_accuracy.append(accuracy)\n",
    "            \n",
    "            #Backpropagation to calculate gradients\n",
    "            \n",
    "            loss.backward()\n",
    "            intermediate_end = time.time()\n",
    "            \n",
    "            # Making sure gradient flow is behaving as expected \n",
    "            if batch_idx % 300 == 0:\n",
    "                plot_grad_flow(model.named_parameters())\n",
    "                plt.show()\n",
    "                \n",
    "            # Test to ensure that the parameters update properly every 300 mini batches\n",
    "            if batch_idx %300 == 0:\n",
    "                original_params = []\n",
    "                for param in model.parameters():\n",
    "                    original_params.append(param.clone())\n",
    "            \n",
    "            # Perform Parameter Update\n",
    "            optimizer.step() \n",
    "            \n",
    "            # Test to ensure that the parameters update properly every 300 mini batches\n",
    "            if batch_idx % 300 == 0:\n",
    "                for original_param, updated_param in zip(original_params, model.parameters()):\n",
    "                    try:\n",
    "                        (original_param != updated_param).any()\n",
    "                    except:\n",
    "                        print(\"Parameters didn't update this mini-batch\")\n",
    "                print('Test passed, all parameters updated!')\n",
    "                \n",
    "            # Updates during training\n",
    "            if batch_idx % 200 == 0:\n",
    "                print('Batch Index : %s Loss : %.3f Accuracy: %.2f Time : %.3f seconds ' % (batch_idx, np.mean(epoch_loss), np.mean(epoch_accuracy), intermediate_end - start))\n",
    "            \n",
    "        #Put model into eval mode to get validation loss and accuracy \n",
    "        model.eval()\n",
    "        avgLossEpoch = np.mean(epoch_loss)\n",
    "        avgAccuracyEpoch = np.mean(epoch_accuracy)\n",
    "        training_loss.append(avgLossEpoch)\n",
    "        training_accuracy.append(avgAccuracyEpoch)\n",
    "        \n",
    "        val_loss, val_accuracy = validation(model, validation_data, cost_function, device)\n",
    "        validation_loss.append(val_loss)\n",
    "        validation_accuracy.append(val_accuracy)        \n",
    "        \n",
    "        model.train()\n",
    "        scheduler.step(val_loss)\n",
    "        end = time.time()\n",
    "        print('Time for epoch %s is %.2f s, Training Loss: %.3f, Training Accuracy: %.3f, Validation Loss: %.3f, Validation Accuracy: %.3f'%(epoch, end-start, avgLossEpoch, avgAccuracyEpoch, val_loss, val_accuracy))\n",
    "    return training_loss, validation_loss, training_accuracy, validation_accuracy, epochNum\n",
    "\n",
    "def validation(model, validation_data, cost_function, device):\n",
    "    with torch.no_grad():\n",
    "        loss = [] \n",
    "        accuracy = [] \n",
    "        for inputs, targets in validation_data:\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            cost = cost_function(outputs, targets)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total = len(targets)\n",
    "            correct = int(torch.sum(predicted == targets.data))\n",
    "            accuracy.append((correct/total)*100)\n",
    "            loss.append(cost.item())\n",
    "        return np.mean(loss), np.mean(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_grad_flow(named_parameters):\n",
    "    ave_grads, max_grads, layers = getGradientsOfNetwork(named_parameters)\n",
    "    plt.figure(figsize=(20, 6))\n",
    "    plt.bar(np.arange(len(ave_grads)), max_grads, alpha=0.1, lw=1, color=\"c\")\n",
    "    plt.bar(np.arange(len(ave_grads)), ave_grads, alpha=0.1, lw=1, color=\"b\")\n",
    "    plt.hlines(0, 0, len(ave_grads)+1, lw=2, color=\"k\" )\n",
    "    plt.xticks(range(0,len(ave_grads), 1), layers, rotation=\"vertical\")\n",
    "    plt.xlabel(\"Layers\")\n",
    "    plt.ylabel(\"average gradient\")\n",
    "    plt.title(\"Gradient flow\")\n",
    "    plt.grid(True)\n",
    "    plt.legend([Line2D([0], [0], color=\"c\", lw=4),\n",
    "                Line2D([0], [0], color=\"b\", lw=4),\n",
    "                Line2D([0], [0], color=\"k\", lw=4)], ['max-gradient', 'mean-gradient', 'zero-gradient'])\n",
    "    \n",
    "def getGradientsOfNetwork(named_parameters):\n",
    "    layers = []\n",
    "    avg_grad = []\n",
    "    max_grad = []\n",
    "    for n, p in named_parameters:\n",
    "        if(p.requires_grad) and (\"bias\" not in n):\n",
    "            layers.append(n)\n",
    "            avg_grad.append(p.grad.abs().mean())\n",
    "            max_grad.append(p.grad.abs().max())\n",
    "    return avg_grad, max_grad, layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_loss, validation_loss, training_accuracy, validation_accuracy, epochNum = trainResNet(epochs = 135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeTrainValidationLoss(training_loss, validation_loss, trainAcc, validAcc, epochNum):\n",
    "    plt.figure(figsize = (10,6))\n",
    "    plt.plot(epochNum, training_loss)\n",
    "    plt.plot(epochNum, validation_loss,)\n",
    "    plt.xlabel('Number of Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.show() \n",
    "    \n",
    "    plt.figure(figsize = (10,6))\n",
    "    plt.plot(epochNum, trainAcc)\n",
    "    plt.plot(epochNum, validAcc)\n",
    "    plt.xlabel('Number of Epochs')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualizeTrainValidationLoss(training_loss, validation_loss, training_accuracy, validation_accuracy, epochNum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 32, 32]           1,728\n",
      "       BatchNorm2d-2           [-1, 64, 32, 32]             128\n",
      "            Conv2d-3           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-4           [-1, 64, 32, 32]             128\n",
      "            Conv2d-5           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-6           [-1, 64, 32, 32]             128\n",
      "          ResBlock-7           [-1, 64, 32, 32]               0\n",
      "            Conv2d-8           [-1, 64, 32, 32]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 32, 32]             128\n",
      "           Conv2d-10           [-1, 64, 32, 32]          36,864\n",
      "      BatchNorm2d-11           [-1, 64, 32, 32]             128\n",
      "         ResBlock-12           [-1, 64, 32, 32]               0\n",
      "           Conv2d-13          [-1, 128, 16, 16]          73,728\n",
      "      BatchNorm2d-14          [-1, 128, 16, 16]             256\n",
      "           Conv2d-15          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-16          [-1, 128, 16, 16]             256\n",
      "           Conv2d-17          [-1, 128, 16, 16]           8,192\n",
      "      BatchNorm2d-18          [-1, 128, 16, 16]             256\n",
      "         ResBlock-19          [-1, 128, 16, 16]               0\n",
      "           Conv2d-20          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-21          [-1, 128, 16, 16]             256\n",
      "           Conv2d-22          [-1, 128, 16, 16]         147,456\n",
      "      BatchNorm2d-23          [-1, 128, 16, 16]             256\n",
      "         ResBlock-24          [-1, 128, 16, 16]               0\n",
      "           Conv2d-25            [-1, 256, 8, 8]         294,912\n",
      "      BatchNorm2d-26            [-1, 256, 8, 8]             512\n",
      "           Conv2d-27            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-28            [-1, 256, 8, 8]             512\n",
      "           Conv2d-29            [-1, 256, 8, 8]          32,768\n",
      "      BatchNorm2d-30            [-1, 256, 8, 8]             512\n",
      "         ResBlock-31            [-1, 256, 8, 8]               0\n",
      "           Conv2d-32            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-33            [-1, 256, 8, 8]             512\n",
      "           Conv2d-34            [-1, 256, 8, 8]         589,824\n",
      "      BatchNorm2d-35            [-1, 256, 8, 8]             512\n",
      "         ResBlock-36            [-1, 256, 8, 8]               0\n",
      "           Conv2d-37            [-1, 512, 4, 4]       1,179,648\n",
      "      BatchNorm2d-38            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-39            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-40            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-41            [-1, 512, 4, 4]         131,072\n",
      "      BatchNorm2d-42            [-1, 512, 4, 4]           1,024\n",
      "         ResBlock-43            [-1, 512, 4, 4]               0\n",
      "           Conv2d-44            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-45            [-1, 512, 4, 4]           1,024\n",
      "           Conv2d-46            [-1, 512, 4, 4]       2,359,296\n",
      "      BatchNorm2d-47            [-1, 512, 4, 4]           1,024\n",
      "         ResBlock-48            [-1, 512, 4, 4]               0\n",
      "           Linear-49                   [-1, 10]           5,130\n",
      "================================================================\n",
      "Total params: 11,173,962\n",
      "Trainable params: 11,173,962\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 11.25\n",
      "Params size (MB): 42.63\n",
      "Estimated Total Size (MB): 53.89\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(clf, (3,32,32))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
